<!DOCTYPE html>
<html lang="en">
<head>
    <title>Xintao Wang</title>
    <!-- Meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="Xiaoying Riley at 3rd Wave Media">
    <link rel="shortcut icon" href="images/me2.jpg">

    <link href='https://fonts.googleapis.com/css?family=Lato:300,400,300italic,400italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>

    <!-- FontAwesome JS -->
    <script defer src="assets/fontawesome/js/all.js"></script>

    <!-- Global CSS -->
    <link rel="stylesheet" href="assets/plugins/bootstrap/css/bootstrap.min.css">

    <!-- github calendar css -->
    <!-- <link rel="stylesheet" href="assets/plugins/github-calendar/dist/github-calendar-responsive.css"> -->
    <!-- github activity css -->
    <!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/octicons/2.0.2/octicons.min.css"> -->
    <!-- <link rel="stylesheet" href="assets/plugins/github-activity/src/github-activity.css"> -->

    <!-- Theme CSS -->
    <link id="theme-style" rel="stylesheet" href="assets/css/styles.css">

</head>

<body>
    <!-- ******HEADER****** -->
    <header class="header">
        <div class="container">
	        <div class="row align-items-center">
			    <div class="col">
		            <!-- <img class="profile-image img-fluid float-start rounded-circle" src="images/me2.jpg" alt="profile image" /> -->
                    <img class='profile-image img-fluid float-start rounded-circle' src="images/me2.jpg" alt="profile image"
                        onmouseover="this.src='images/daodao_draw_180.jpg'"
                        onmouseout="this.src='images/me2.jpg'" />
		            <div class="profile-content">
		                <h1 class="name">Xintao Wang</h1>
		                <!-- <h2 class="desc">Web App Developer</h2> -->
		                <ul class="social list-inline">
		                    <li class="list-inline-item"><a href="https://twitter.com/_Xintao_" target="_blank"><i class="fab fa-twitter"></i></a></li>
		                    <!-- <li class="list-inline-item"><a href="#"><i class="fab fa-linkedin-in"></i></a></li> -->
                            <li class="list-inline-item"><a href="https://scholar.google.com.hk/citations?user=FQgZpQoAAAAJ&hl=en" target="_blank"><i class="fab fa-google"></i></a></li>
		                    <li class="list-inline-item"><a href="https://github.com/xinntao" target="_blank"><i class="fab fa-github"></i></a></li>
		                    <li class="list-inline-item"><a href="email.html" target="_blank"><i class="fas fa-envelope-square"></i></a></li>
                            <li class="list-inline-item last-item"><a href="https://www.zhihu.com/people/xintao-28" target="_blank"><i class="fab fa-zhihu"></i></a></li>
		                </ul>
		            </div><!--//profile-->
			    </div><!--//col-->
	            <div class="col-12 col-md-auto">
		            <div class="dark-mode-switch d-flex">
						<div class="form-check form-switch mx-auto mx-md-0">
							<input type="checkbox" class="form-check-input me-2" id="darkSwitch"/>
							<label class="custom-control-label" for="darkSwitch">Dark Mode</label>
						</div>
			        </div><!--//dark-mode-switch-->
	                <a class="btn btn-cta-primary" href="email.html" target="_blank"><i class="fas fa-paper-plane"></i> Contact Me</a>
	            </div><!--//col-->
	        </div><!--//row-->
        </div><!--//container-->
    </header><!--//header-->

    <div class="container sections-wrapper py-5">
        <div class="row">
            <div class="primary col-lg-8 col-12">
                <section class="about section">
                    <div class="section-inner shadow-sm rounded">
                        <!-- <h2 class="heading">About Me</h2> -->
                        <div class="content">
                            I am currently a principal researcher at <a href="https://arc.tencent.com/" target="_blank">Tencent ARC Lab</a> and <a href="https://ai.tencent.com/ailab/en/index/" target="_blank">Tencent AI Lab</a>.
                            </p>
                            <p align="left">
                                Previously, I got my Ph.D. degree from <a href="http://mmlab.ie.cuhk.edu.hk/" target="_blank">Multimedia
                                Laboratory (MMLab)</a>,
                                <a href="https://www.cuhk.edu.hk/english/index.html" target="_blank">the Chinese University of Hong Kong</a>, advised by Prof. <a href="http://personal.ie.cuhk.edu.hk/~ccloy/" target="_blank">Chen Change Loy</a> and Prof. <a
                                href="https://scholar.google.com/citations?user=qpBtpGsAAAAJ" target="_blank">Xiaoou Tang</a>.
                                I also work closely with Prof. <a href=" https://scholar.google.com.hk/citations?user=OSDCB0UAAAAJ"
                                target="_blank">Chao Dong</a>.
                                Earlier, I obtained my bachelor's degree from  <a href="https://www.zju.edu.cn/english/" target="_blank">Zhejiang University</a>.
                            </p>
                            <p align="left">
                                My research interests focus on <b>visual content generation and editing (AIGC-related topics)</b>.
                                <font color="orange"><b>We are actively looking for research interns to work on AIGC-related research topics, including but not limited to image and video generation/editing</b></font>. Please feel free to drop me an email to <font color="orange"><a href="mailto:xintaowang@tencent.com">xintaowang@tencent.com</a></font> if you are interested.
                        </div><!--//content-->
                    </div><!--//section-inner-->
                </section><!--//section-->

<!--=====================================================  News  ====================================================-->
                <section class="projects section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">News</h2>
                        <div class="item-content">
                            <ul class="resume-list" style="list-style: outside;list-style-type: square;">
                                <li> <b>[07/2023]</b> Three papers are accepted to ICCV 2023.</li>
                                <li> <b>[04/2023]</b> One paper is accepted to ICML 2023.</li>
                                <li> <b>[03/2023]</b> We are holding the <a href="https://github.com/360SR/360SR-Challenge" target="_blank">360Â° Super-Resolution Challenge</a> as a part of the <a href="https://cvlai.net/ntire/2023/" target="_blank">NTIRE workshop</a> in conjunction with CVPR 2023.</li>
                                <li> <b>[02/2023]</b> Three papers to appear in CVPR 2023.</li>
                                <li> <b>[11/2022]</b> Two papers to appear in AAAI 2023.</li>
                                <li> <b>[09/2022]</b> Two papers to appear in NeurIPS 2022.</li>
                                <li> <b>[07/2022]</b> Two papers to appear in ECCV 2022. VQFR is accepted as <font color="orange">oral</font> (2.7%).</li>
                                <li> <b>[06/2022]</b> Two papers to appear in ACM MM 2022.</li>
                                <li> <b>[05/2022]</b> BasicSR joins the <a href="https://github.com/XPixelGroup" target="_blank">XPixel Group</a>!</li>
                                <li> <b>[04/2022]</b> We release a high-quality face video dataset (VFHQ). Please refer to the <a href="https://liangbinxie.github.io/projects/vfhq">project page</a> and <a href="https://arxiv.org/abs/2205.03409">our paper</a>.</li>
                                <li> <b>[12/2021]</b> One paper to appear in NeurIPS 2021 as <font color="orange">spotlight</font> (2.85%): <a href="https://proceedings.neurips.cc/paper/2021/hash/008bd5ad93b754d500338c253d9c1770-Abstract.html">FAIG: Finding Discriminative Filters for Specific Degradations in Blind Super-Resolution</a>. Codes are released in <a href="https://github.com/TencentARC/FAIG">TencentARC/FAIG</a>.</li>
                                <li> <b>[10/2021]</b> <a href="https://arxiv.org/abs/2107.10833">Real-ESRGAN</a> is accepted by ICCV 2021 AIM workshop with Honorary Nomination Paper Award.</li>
                                <details>
                                    <summary>Click for More</summary>
                                <li> [07/2021] One paper to appear in ICCV 2021: <a href="https://arxiv.org/abs/2108.08826">Towards Vivid and Diverse
                                    Image Colorization with Generative Color Prior</a>
                                </li>
                                <li> [07/2021] The codes for practical image restoration <a href="https://arxiv.org/abs/2107.10833">Real-ESRGAN</a>
                                    are released on <a href="https://github.com/xinntao/Real-ESRGAN">Github</a>.
                                </li>
                                <li> [06/2021] The training and testing codes of GFPGAN are released on <a
                                    href="https://github.com/TencentARC/GFPGAN">TencentARC</a>.
                                </li>
                                <li> [03/2021] 5 papers to appear in CVPR 2021.
                                </li>
                                <li> [03/2021] A brand-new <a href="https://github.com/xinntao/HandyView">HandyView</a> online!.
                                </li>
                                <li> [08/2020] A brand-new <a href="https://github.com/xinntao/BasicSR">BasicSR</a> v1.0.0 online!
                                </li>
                                <li> [06/2019] We have released the <a href="https://github.com/xinntao/EDVR">EDVR</a> training and testing codes
                                    and also updated <a href="https://github.com/xinntao/BasicSR">BasicSR</a> codes!
                                </li>
                                <li> [06/2019] Got my first outstanding reviewer recognition from CVPR 2019!
                                </li>
                                <li> [05/2019] Our video restoration method, <b>EDVR</b>, won all four tracks in the <a
                                    href="http://www.vision.ee.ethz.ch/ntire19/">NTIRE 2019 video restoration and enhancement challenges</a>.
                                    Check <a href="https://arxiv.org/abs/1905.02716">our paper</a> for more details.
                                </li>
                                <li> [03/2019] Our paper <a href="https://xinntao.github.io/projects/DNI"><i>Deep Network Interpolation for
                                        Continuous Imagery Effect Transition</i></a> to appear in CVPR 2019.
                                </li>
                                <li> [08/2018] Our SuperSR team won the third track of the <a href="https://www.pirm2018.org/PIRM-SR.html">2018
                                    PIRM Challenge on Perceptual Super-Resolution</a>. Check the report <a
                                    href="https://arxiv.org/abs/1809.00219"><i>ESRGAN</i></a> for more details.
                                </li>
                                <li> [06/2018] We won the <a href="http://www.vision.ee.ethz.ch/ntire17/NTIRE">NTIRE 2018 Challenge on Single Image
                                    Super-Resolution</a> as first runner-up and ranked the first in the <i>Realistic Wild Ã4 conditions</i>
                                    track.
                                </li>
                                <li> [02/2018] Our paper <a href="http://mmlab.ie.cuhk.edu.hk/projects/SFTGAN/"><i>Recovering Realistic Texture in
                                        Image Super-resolution by Deep Spatial Feature Transform</i></a> to appear in CVPR 2018.
                                </li>
                                <li> [07/2017] Our HelloSR team won the <a href="http://www.vision.ee.ethz.ch/ntire17/NTIRE">NTIRE 2017 Challenge
                                    on Single Image Super-Resolution</a> as first runner-up.
                                </li>
                                </details>
                            </ul>
                        </div><!--//content-->
                    </div><!--//section-inner-->
                </section><!--//section-->

<!--=====================================================  Publications  ====================================================-->
               <section class="latest section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">Publications <a href="https://scholar.google.com.hk/citations?user=FQgZpQoAAAAJ&hl=en" target="_blank">[Full List]</a></h2>
                        <div class="content">
                                <small>(* equal contribution, <sup>#</sup> corresponding author)</small>
                        <br>
                            <!-- <hr class="divider" /> -->

                        <!------------------------------------------ Template ----------------------------------->
                            <!-- <div class="item row">
                                <a class="col-md-4 col-12" href="ãprojectpage linkã" target="_blank">
                                <img class="img-fluid project-image rounded shadow-sm" src="ã./images/masactrl.pngã" alt="teaser" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"><a href="ãarticle linkã" target="_blank">ãarticle nameã</a></h3>
                                    <p class="mb-2"><b>Xintao Wang<sup>#</sup></b>ãauthorsã</p>
                                    <p>
                                        arXiv preprint, 2023. &nbsp;
                                        <a class="more-link" href="ãã" target="_blank"><i class="fas fa-external-link-alt"></i>Project Page</a>&nbsp;
                                        <a class="more-link" href="ãã" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="ãã" target="_blank"><i class="fab fa-github"></i>Codes</a>&nbsp;
                                        <a class="more-link" href="ãã" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/TencentARC/T2I-Adapter?style=social"></a>
                                    </p>
                                </div>
                            </div> -->
                        <font color="#49ac43"><b>Seleted Preprint</b></font>
                        <!------------------------------------------ T2I-Adapter ----------------------------------->
                            <div class="item row">
                                <a class="col-md-4 col-12" href="https://github.com/TencentARC/T2I-Adapter" target="_blank">
                                <img class="img-fluid project-image rounded shadow-sm" src="./images/t2i-adapter-car.png" alt="teaser" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h4 class="title"><a href="https://arxiv.org/abs/2302.08453" target="_blank">T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models</a></h4>
                                    <p class="mb-2">Chong Mou, <b>Xintao Wang<sup>#</sup></b>, Liangbin Xie, Yanze Wu, Jian Zhang<sup>#</sup>, Zhongang Qi, Ying Shan, Xiaohu Qie</p>
                                    <p>
                                        arXiv preprint, 2023. &nbsp;
                                        <a class="more-link" href="https://arxiv.org/abs/2302.08453" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/T2I-Adapter" target="_blank"><i class="fab fa-github"></i>Codes</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/T2I-Adapter" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/TencentARC/T2I-Adapter?style=social"></a>
                                    </p>
                                </div><!--//desc-->
                            </div><!--//item-->

                            <!------------------------------------------ FollowYourPose ----------------------------------->
                            <div class="item row">
                                <a class="col-md-4 col-12" href="https://follow-your-pose.github.io/" target="_blank">
                                <video autoplay controls="" muted loop playsinline="" width="100%" style="width: 260px"><source src="./images/follow-your-pose.mp4" type="video/mp4"></video>
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"><a href="https://arxiv.org/abs/2304.01186" target="_blank">Follow Your Pose: Pose-Guided Text-to-Video Generation using Pose-Free Videos</a></h3>
                                    <p class="mb-2">Yue Ma, Yingqing He, Xiaodong Cun, <b>Xintao Wang</b>, Ying Shan, Xiu Li, Qifeng Chen</p>
                                    <p>
                                        arXiv preprint, 2023. &nbsp;
                                        <a class="more-link" href="https://follow-your-pose.github.io/" target="_blank"><i class="fas fa-external-link-alt"></i>Project Page</a>&nbsp;
                                        <a class="more-link" href="https://arxiv.org/abs/2304.01186" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="https://github.com/mayuelala/FollowYourPose" target="_blank"><i class="fab fa-github"></i>Codes</a>&nbsp;
                                        <a class="more-link" href="https://github.com/mayuelala/FollowYourPose" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/mayuelala/FollowYourPose?style=social"></a>
                                    </p>
                                </div>
                            </div>

                        <font color="#49ac43"><b>2023</b></font>

                            <!------------------------------------------ MasaCtrl ----------------------------------->
                            <div class="item row">
                                <a class="col-md-4 col-12" href="https://ljzycmd.github.io/projects/MasaCtrl/" target="_blank">
                                <img class="img-fluid project-image rounded shadow-sm" src="./images/masactrl.png" alt="teaser" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"><a href="https://arxiv.org/abs/2304.08465" target="_blank">MasaCtrl: Tuning-Free Mutual Self-Attention Control for Consistent Image Synthesis and Editing</a></h3>
                                    <p class="mb-2">Mingdeng Cao, <b>Xintao Wang<sup>#</sup></b>, Zhongang Qi, Ying Shan, Xiaohu Qie, Yinqiang Zheng<sup>#</sup></p>
                                    <p>
                                        ICCV, 2023. &nbsp;
                                        <a class="more-link" href="https://ljzycmd.github.io/projects/MasaCtrl" target="_blank"><i class="fas fa-external-link-alt"></i>Project Page</a>&nbsp;
                                        <a class="more-link" href="https://arxiv.org/abs/2304.08465" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/MasaCtrl" target="_blank"><i class="fab fa-github"></i>Codes</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/MasaCtrl" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/TencentARC/MasaCtrl?style=social"></a>
                                    </p>
                                </div>
                            </div>

                            <!------------------------------------------ Tune-A-Video ----------------------------------->
                            <div class="item row">
                                <a class="col-md-4 col-12" href="https://tuneavideo.github.io" target="_blank">
                                <img class="img-fluid project-image rounded shadow-sm" src="./images/tuneavideo.gif" alt="teaser" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"><a href="https://arxiv.org/abs/2212.11565" target="_blank">Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation</a></h3>
                                    <p class="mb-2">Jay Zhangjie Wu, Yixiao Ge, <b>Xintao Wang</b>, Weixian Lei, Yuchao Gu, Yufei Shi, Wynne Hsu, Ying Shan, Xiaohu Qie, Mike Zheng Shou</p>
                                    <p>
                                        ICCV, 2023. &nbsp;
                                        <a class="more-link" href="https://tuneavideo.github.io/" target="_blank"><i class="fas fa-external-link-alt"></i>Project Page</a>&nbsp;
                                        <a class="more-link" href="https://arxiv.org/abs/2212.11565" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="https://github.com/showlab/Tune-A-Video" target="_blank"><i class="fab fa-github"></i>Codes</a>&nbsp;
                                        <a class="more-link" href="https://github.com/showlab/Tune-A-Video" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/showlab/Tune-A-Video?style=social"></a>
                                    </p>
                                </div>
                            </div>

                            <!------------------------------------------ FateZero ----------------------------------->
                            <div class="item row">
                                <a class="col-md-4 col-12" href="https://fate-zero-edit.github.io/" target="_blank">
                                <video autoplay controls="" muted loop playsinline="" width="100%" style="width: 260px"><source src="./images/fatezero.mp4" type="video/mp4"></video>
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"><a href="https://arxiv.org/abs/2303.09535" target="_blank">Fate/Zero: Fusing Attentions for Zero-shot Text-based Video Editing</a></h3>
                                    <p class="mb-2">Chenyang Qi, Xiaodong Cun, Yong Zhang, Chenyang Lei, <b>Xintao Wang</b>, Ying Shan, Qifeng Chen</p>
                                    <p>
                                        ICCV, 2023. &nbsp;
                                        <a class="more-link" href="https://fate-zero-edit.github.io/" target="_blank"><i class="fas fa-external-link-alt"></i>Project Page</a>&nbsp;
                                        <a class="more-link" href="https://arxiv.org/abs/2303.09535" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="https://github.com/ChenyangQiQi/FateZero" target="_blank"><i class="fab fa-github"></i>Codes</a>&nbsp;
                                        <a class="more-link" href="https://github.com/ChenyangQiQi/FateZero" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/ChenyangQiQi/FateZero?style=social"></a>
                                    </p>
                                </div>
                            </div>

                            <!------------------------------------------ DeSRA ----------------------------------->
                            <div class="item row">
                                <a class="col-md-4 col-12" href="https://github.com/TencentARC/DeSRA" target="_blank">
                                <img class="img-fluid project-image rounded shadow-sm" src="./images/DeSRA.jpg" alt="teaser" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"><a href="https://arxiv.org/abs/2307.02457" target="_blank">DeSRA: Detect and Delete the Artifacts of GAN-based Real-World Super-Resolution Models</a></h3>
                                    <p class="mb-2">Liangbin Xie*, <b>Xintao Wang*</b>, Xiangyu Chen*, Gen Li, Ying Shan, Jiantao Zhou, Chao Dong</p>
                                    <p>
                                        ICML, 2023. &nbsp;
                                        <!-- <a class="more-link" href="https://fate-zero-edit.github.io/" target="_blank"><i class="fas fa-external-link-alt"></i>Project Page</a>&nbsp; -->
                                        <a class="more-link" href="https://arxiv.org/abs/2307.02457" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/DeSRA" target="_blank"><i class="fab fa-github"></i>Codes</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/DeSRA" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/TencentARC/DeSRA?style=social"></a>
                                    </p>
                                </div>
                            </div>

                            <!------------------------------------------ Dream3D ----------------------------------->
                            <div class="item row">
                                <a class="col-md-4 col-12" href="https://bluestyle97.github.io/dream3d/" target="_blank">
                                <video autoplay="" controls="" muted="" loop="" playsinline="" width="100%" style="width: 240px"><source src="./images/dream3d_car.mp4" type="video/mp4"></video>
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"><a href="https://arxiv.org/abs/2212.14704" target="_blank">Dream3D: Zero-Shot Text-to-3D Synthesis Using 3D Shape Prior and Text-to-Image Diffusion Models</a></h3>
                                    <p class="mb-2">Jiale Xu,
                                        <b>Xintao Wang<sup>#</sup></b>,
                                        Weihao Cheng,
                                        Yan-Pei Cao,
                                        Ying Shan,
                                        Xiaohu Qie,
                                        Shenghua Gao<sup>#</sup></p>
                                    <p>
                                        CVPR, 2023. &nbsp;
                                        <a class="more-link" href="https://bluestyle97.github.io/dream3d" target="_blank"><i class="fas fa-external-link-alt"></i>Project Page</a>&nbsp;
                                        <a class="more-link" href="https://arxiv.org/abs/2212.14704" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="" target="_blank"><i class="fab fa-github"></i>Codes (Coming Soon)</a>&nbsp;
                                        <!-- <a class="more-link" href="ãã" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/TencentARC/T2I-Adapter?style=social"></a> -->
                                    </p>
                                </div>
                            </div>

                            <!------------------------------------------ OSRT ----------------------------------->
                            <div class="item row">
                                <a class="col-md-4 col-12" href="https://github.com/Fanghua-Yu/OSRT" target="_blank">
                                <img class="img-fluid project-image rounded shadow-sm" src="./images/osrt.jpg" alt="teaser" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"><a href="https://arxiv.org/abs/2302.03453" target="_blank">OSRT: Omnidirectional Image Super-Resolution with Distortion-aware Transformer</a></h3>
                                    <p class="mb-2">Fanghua Yu*,
                                        <b>Xintao Wang*</b>,
                                        Mingdeng Cao,
                                        Gen Li,
                                        Ying Shan,
                                        Chao Dong<sup>#</sup></p>
                                    <p>
                                        CVPR, 2023. &nbsp;
                                        <!-- <a class="more-link" href="ãã" target="_blank"><i class="fas fa-external-link-alt"></i>Project Page</a>&nbsp; -->
                                        <a class="more-link" href="https://arxiv.org/abs/2302.03453" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="https://github.com/Fanghua-Yu/OSRT" target="_blank"><i class="fab fa-github"></i>Codes</a>&nbsp;
                                        <a class="more-link" href="https://github.com/Fanghua-Yu/OSRT" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/Fanghua-Yu/OSRT?style=social"></a>
                                    </p>
                                </div>
                            </div>

                            <!------------------------------------------ HAT ----------------------------------->
                            <div class="item row">
                                <a class="col-md-4 col-12" href="https://github.com/XPixelGroup/HAT" target="_blank">
                                <img class="img-fluid project-image rounded shadow-sm" src="./images/HAT.png" alt="teaser" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"><a href="https://arxiv.org/abs/2205.04437" target="_blank"><b>HAT</b>: Activating More Pixels in Image Super-Resolution Transformer</a></h3>
                                    <p class="mb-2">Xiangyu Chen,
                                        <b>Xintao Wang</b>,
                                        <a href="https://scholar.google.com.hk/citations?user=mcROAxAAAAAJ&hl=en" target="_blank">Jiantao Zhou</a>,
                                        <a href="https://scholar.google.com.hk/citations?user=OSDCB0UAAAAJ" target="_blank">Chao Dong</a></p>
                                    <p>
                                        CVPR, 2023. &nbsp;
                                        <!-- <a class="more-link" href="ãã" target="_blank"><i class="fas fa-external-link-alt"></i>Project Page</a>&nbsp; -->
                                        <a class="more-link" href="https://arxiv.org/abs/2205.04437" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="https://github.com/XPixelGroup/HAT" target="_blank"><i class="fab fa-github"></i>Codes</a>&nbsp;
                                        <a class="more-link" href="https://github.com/XPixelGroup/HAT" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/XPixelGroup/HAT?style=social"></a>
                                    </p>
                                </div>
                            </div>

                            <!------------------------------------------ FastRealVSR ----------------------------------->
                            <div class="item row">
                                <a class="col-md-4 col-12" href="https://github.com/TencentARC/FastRealVSR" target="_blank">
                                <img class="img-fluid project-image rounded shadow-sm" src="./images/FastRealVSR.jpg" alt="teaser" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"><a href="https://arxiv.org/abs/2212.07339" target="_blank">Mitigating Artifacts in Real-World Video Super-Resolution Models</a></h3>
                                    <p class="mb-2">Liangbin Xie, <b>Xintao Wang</b>, Shuwei Shi, Jinjin Gu, Chao Dong, Ying Shan</p>
                                    <p>
                                        AAAI, 2022. &nbsp;
                                        <!-- <a class="more-link" href="https://arxiv.org/abs/2212.07339" target="_blank"><i class="fas fa-external-link-alt"></i>Project Page</a>&nbsp; -->
                                        <a class="more-link" href="https://arxiv.org/abs/2212.07339" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/FastRealVSR" target="_blank"><i class="fab fa-github"></i>Codes</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/FastRealVSR" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/TencentARC/FastRealVSR?style=social"></a>
                                    </p>
                                </div>
                            </div>

                            <!------------------------------------------ Accelerate ----------------------------------->
                            <div class="item row">
                                <a class="col-md-4 col-12" href="https://arxiv.org/abs/2205.05069" target="_blank">
                                <img class="img-fluid project-image rounded shadow-sm" src="./images/EfficientVSRTraining.png" alt="teaser" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"><a href="https://arxiv.org/abs/2205.05069" target="_blank">Accelerating the Training of Video Super-resolution Models</a></h3>
                                    <p class="mb-2">Lijian Lin, <b>Xintao Wang<sup>#</sup></b>, Zhongang Qi, Ying Shan</p>
                                    <p>
                                        AAAI, 2022. &nbsp;
                                        <!-- <a class="more-link" href="https://arxiv.org/abs/2212.07339" target="_blank"><i class="fas fa-external-link-alt"></i>Project Page</a>&nbsp; -->
                                        <a class="more-link" href="https://arxiv.org/abs/2205.05069" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/Efficient-VSR-Training" target="_blank"><i class="fab fa-github"></i>Codes</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/Efficient-VSR-Training" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/TencentARC/Efficient-VSR-Training?style=social"></a>
                                    </p>
                                </div>
                            </div>

                            <font color="#49ac43"><b>2022</b></font>


                            <!------------------------------------------ AnimeSR ----------------------------------->
                            <div class="item row">
                                <a class="col-md-4 col-12" href="https://github.com/TencentARC/AnimeSR" target="_blank">
                                <img class="img-fluid project-image rounded shadow-sm" src="./images/animesr.jpg" alt="teaser" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"><a href="https://arxiv.org/abs/2206.07038" target="_blank">AnimeSR: Learning Real-World Super-Resolution Models for Animation Videos</a></h3>
                                    <p class="mb-2">Yanze Wu*,
                                        <b>Xintao Wang*</b>,
                                        Gen Li,
                                        <a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en" target="_blank">Ying Shan</a></p>
                                    <p>
                                        NeurIPS, 2022. &nbsp;
                                        <!-- <a class="more-link" href="ãã" target="_blank"><i class="fas fa-external-link-alt"></i>Project Page</a>&nbsp; -->
                                        <a class="more-link" href="https://arxiv.org/abs/2206.07038" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/AnimeSR" target="_blank"><i class="fab fa-github"></i>Codes</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/AnimeSR" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/TencentARC/AnimeSR?style=social"></a>
                                    </p>
                                </div>
                            </div>

                            <!------------------------------------------ Rethinking Alignment ----------------------------------->
                            <div class="item row">
                                <a class="col-md-4 col-12" href="https://github.com/XPixelGroup/RethinkVSRAlignment" target="_blank">
                                <img class="img-fluid project-image rounded shadow-sm" src="./images/rethink_alignment.jpg" alt="teaser" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"><a href="https://arxiv.org/abs/2207.08494" target="_blank">Rethinking Alignment in Video Super-Resolution Transformers</a></h3>
                                    <p class="mb-2">Shuwei Shi, Jinjin Gu, Liangbin Xie, <b>Xintao Wang</b>, Yujiu Yang, Chao Dong</p>
                                    <p>
                                        NeurIPS, 2022. &nbsp;
                                        <!-- <a class="more-link" href="ãã" target="_blank"><i class="fas fa-external-link-alt"></i>Project Page</a>&nbsp; -->
                                        <a class="more-link" href="https://arxiv.org/abs/2207.08494" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="https://github.com/XPixelGroup/RethinkVSRAlignment" target="_blank"><i class="fab fa-github"></i>Codes</a>&nbsp;
                                        <a class="more-link" href="https://github.com/XPixelGroup/RethinkVSRAlignment" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/XPixelGroup/RethinkVSRAlignment?style=social"></a>
                                    </p>
                                </div>
                            </div>

                            <!------------------------------------------ VQFR ----------------------------------->
                            <div class="item row">
                                <a class="col-md-4 col-12" href="https://github.com/TencentARC/VQFR" target="_blank">
                                <img class="img-fluid project-image rounded shadow-sm" src="./images/VQFR.png" alt="teaser" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"><a href="https://arxiv.org/abs/2205.06803" target="_blank">VQFR: Blind Face Restoration with Vector-Quantized Dictionary and Parallel Decoder</a></h3>
                                    <p class="mb-2">Yuchao Gu, <b>Xintao Wang</b>, Liangbie Xie, Chao Dong, Gen Li, Ying Shan, Ming-Ming Cheng</p>
                                    <p>
                                        <b>Selected as Oral (2.7%)</b><br> ECCV, 2022. &nbsp;
                                        <!-- <a class="more-link" href="ãã" target="_blank"><i class="fas fa-external-link-alt"></i>Project Page</a>&nbsp; -->
                                        <a class="more-link" href="https://arxiv.org/abs/2205.06803" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/VQFR" target="_blank"><i class="fab fa-github"></i>Codes</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/VQFR" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/TencentARC/VQFR?style=social"></a>
                                    </p>
                                </div>
                            </div>

                            <!------------------------------------------ MMRealSR ----------------------------------->
                            <div class="item row">
                                <a class="col-md-4 col-12" href="https://github.com/TencentARC/MM-RealSR" target="_blank">
                                <img class="img-fluid project-image rounded shadow-sm" src="./images/MM-RealSR.png" alt="teaser" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"><a href="https://arxiv.org/abs/2205.05065" target="_blank">MM-RealSR: Metric Learning based Interactive Modulation for Real-World Super-Resolution</a></h3>
                                    <p class="mb-2">Chong Mou, Yanze Wu, <b>Xintao Wang</b>, Chao Dong, Jian Zhang, Ying Shan</p>
                                    <p>
                                        ECCV, 2022. &nbsp;
                                        <!-- <a class="more-link" href="ãã" target="_blank"><i class="fas fa-external-link-alt"></i>Project Page</a>&nbsp; -->
                                        <a class="more-link" href="https://arxiv.org/abs/2205.05065" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/MM-RealSR" target="_blank"><i class="fab fa-github"></i>Codes</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/MM-RealSR" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/TencentARC/MM-RealSR?style=social"></a>
                                    </p>
                                </div>
                            </div>



                            <font color="#49ac43"><b>2021</b></font>
                            <!------------------------------------------ Real-ESRGAN ----------------------------------->
                            <div class="item row">
                                <a class="col-md-4 col-12" href="https://github.com/xinntao/Real-ESRGAN" target="_blank">
                                <img class="img-fluid project-image rounded shadow-sm" src="./images/realesrgan_rlt.jpg" alt="teaser" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"><a href="https://arxiv.org/abs/2107.10833" target="_blank">Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data</a></h3>
                                    <p class="mb-2"><b>Xintao Wang</b>,
                                        <a href="https://liangbinxie.github.io/" target="_blank">Liangbie Xie</a>,
                                        <a href="https://scholar.google.com.hk/citations?user=OSDCB0UAAAAJ" target="_blank">Chao Dong</a>,
                                        <a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en" target="_blank">Ying Shan</a></p>
                                    <p>
                                        ICCVW, 2021. &nbsp;
                                        <a class="more-link" href="https://arxiv.org/abs/2107.10833" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="https://github.com/xinntao/Real-ESRGAN" target="_blank"><i class="fab fa-github"></i>Codes</a>&nbsp;
                                        <a class="more-link" href="ãã" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/xinntao/Real-ESRGAN?style=social"></a>
                                    </p>
                                </div>
                            </div>

                            <!------------------------------------------ GFP-GAN ----------------------------------->
                            <div class="item row">
                                <a class="col-md-4 col-12" href="./projects/gfpgan.html" target="_blank">
                                <!-- <img class="img-fluid project-image rounded shadow-sm" src="ãimageã" alt="teaser" /> -->
                                <img class='img-fluid project-image rounded shadow-sm' src="images/gfpgan_lr.jpg" width="350px"
                                    onmouseover="this.src='images/gfpgan_hr.jpg'" width="350px" onmouseout="this.src='images/gfpgan_lr.jpg'"
                                    width="350px" />

                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"><a href="https://arxiv.org/abs/2101.04061" target="_blank"><b>GFPGAN</b>: Towards
                                        Real-World Blind
                                        Face Restoration with Generative Facial Prior</a></h3>
                                    <p class="mb-2"><b>Xintao Wang</b>,
                                        <a href="https://yu-li.github.io" target="_blank">Yu Li</a>,
                                        <a href="https://scholar.google.com/citations?hl=en&user=KjQLROoAAAAJ" target="_blank">Honglun Zhang</a>,
                                        <a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en" target="_blank">Ying Shan</a></p>
                                    <p>
                                        CVPR, 2021. &nbsp;
                                        <a class="more-link" href="./projects/gfpgan.html" target="_blank"><i class="fas fa-external-link-alt"></i>Project Page</a>&nbsp;
                                        <a class="more-link" href="https://arxiv.org/abs/2101.04061" target="_blank"><i class="fas fa-external-link-alt"></i>Paper (arXiv)</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/GFPGAN" target="_blank"><i class="fab fa-github"></i>Codes</a>&nbsp;
                                        <a class="more-link" href="https://github.com/TencentARC/GFPGAN" target="_blank"><img alt="GitHub stars" align="right"
                                            src="https://img.shields.io/github/stars/TencentARC/GFPGAN?style=social"></a>
                                    </p>
                                </div>
                            </div>
                            <font color="#49ac43"><b>To be updated</b></font>


                        </div><!--//content-->
                    </div><!--//section-inner-->
                </section><!--//section-->

            </div><!--//primary-->
            <div class="secondary col-lg-4 col-12">
                 <aside class="info aside section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading sr-only">Basic Information</h2>
                        <div class="content">
                            <ul class="list-unstyled">
                                <li><i class="fas fa-envelope"></i><span class="sr-only">Email:</span><a href="email.html">xintaowang@tencent.com</a></li>
                                <li><i class="fab fa-google"></i><span class="sr-only">Google Scholar:</span><a href="https://scholar.google.com.hk/citations?user=FQgZpQoAAAAJ&hl=en">Google Scholar</a></li>
                                <li><i class="fab fa-github"></i><span class="sr-only">GitHub:</span><a href="https://github.com/xinntao">GitHub</a></li>
                                <li><i class="fas fa-map-marker-alt"></i><span class="sr-only">Location:</span>Shenzhen, China</li>
                                <!-- <li><i class="fas fa-link"></i><span class="sr-only">Website:</span><a href="#">https://www.website.com</a></li> -->
                            </ul>
                        </div><!--//content-->
                    </div><!--//section-inner-->
                </aside><!--//aside-->

                <aside class="education aside section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">Education</h2>
                        <div class="content">
                            <div class="item">
                                <h3 class="title"><i class="fas fa-graduation-cap"></i> Ph.D.</h3>
                                <h4 class="university"><a href="http://mmlab.ie.cuhk.edu.hk/" target="_blank">Multimedia
              Laboratory (MMLab)</a>,<br>
            <a href="https://www.cuhk.edu.hk/english/index.html" target="_blank">The Chinese University of Hong Kong</a> <span class="year"></span></h4>
                            </div><!--//item-->
                            <div class="item">
                                <h3 class="title"><i class="fas fa-graduation-cap"></i> B.Eng.</h3>
                                <h4 class="university"> <a href="https://www.zju.edu.cn/english/" target="_blank">Zhejiang University</a><span class="year"></span></h4>
                            </div><!--//item-->
                        </div><!--//content-->
                    </div><!--//section-inner-->

            <script type='text/javascript' id='clustrmaps'
                src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=67did0CAdncq-M1USj88a8nvNyHJzr771w9jz5KE4sQ&co=2d78ad&ct=ffffff&cmo=3acc3a&cmn=ff5353'>
            </script>

                </aside><!--//section-->

            </div><!--//secondary-->
        </div><!--//row-->
    </div><!--//masonry-->

    <!-- ******FOOTER****** -->
    <footer class="footer">
        <div class="container text-center">
                <!--/* This template is free as long as you keep the attribution link below. Thank you for your support. :) If you'd like to use the template without the attribution, you can buy the commercial license via our website: themes.3rdwavemedia.com */-->
                <small class="copyright">This template is modified from <a href="https://themes.3rdwavemedia.com/demo/bs5/developer/" target="_blank">Xiaoying Riley's project</a></small>
        </div><!--//container-->
    </footer><!--//footer-->

    <!-- Javascript -->
    <script type="text/javascript" src="assets/plugins/popper.min.js"></script>
    <script type="text/javascript" src="assets/plugins/bootstrap/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="assets/plugins/vanilla-rss/dist/rss.global.min.js"></script>
    <script type="text/javascript" src="assets/plugins/dark-mode-switch/dark-mode-switch.min.js"></script>
    <!-- custom js -->
    <script type="text/javascript" src="assets/js/main.js"></script>
</body>
</html>

